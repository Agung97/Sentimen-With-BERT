# Bidirectional Encoder Representation from Transformer

BERT (Bidirectional Encoder Representation from Transformer) adalah model berbasis transformer yang telah dilatih sebelumnya pada korpus besar data teks. BERT mampu menangkap informasi kontekstual dari teks input sehingga menjadi sangat efektif untuk tugas pemahaman pada NLP
